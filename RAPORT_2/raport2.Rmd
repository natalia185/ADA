---
title: "Raport 2"
author: "Natalia Iwańska 262270, Klaudia Janicka 262268"
date: "`r Sys.Date()`"
output: pdf_document
fig_caption: yes
header-includes:
  \usepackage{booktabs}
  \usepackage{float}
  \renewcommand{\tablename}{Tab.}
  \renewcommand{\figurename}{Wykres}
  \floatplacement{figure}{H}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
knitr::opts_chunk$set(fig.width=8, fig.height=4.5) 
pdf.options(encoding = 'CP1250')
```

```{r, include=FALSE, echo=FALSE}
library("tidyverse")
library("vcd")
library("ggplot2")
library("knitr")
library("dplyr")
library("xtable")
library("kableExtra")
library("ggplot2")
library('likert')
library("binom")
library("DescTools")
library(pracma)
library(ca)
library(psych)
```

```{r, include=FALSE, echo=FALSE}
personel <- read.csv2('data//personel.csv',header=FALSE)
names(personel) <- c('D','S','A1','A2','W1','W2','P','Wiek','Wyk')
personel$A2[personel$A2 == '11'] = '1'
personel <- personel %>% mutate(across(D:Wyk,as.factor))
```

# Zadanie 2

Przy pomocy testu Fishera na poziomie istotności $\alpha = 0.05$ zweryfikowano następującą hipotezę:

$H_0 \colon$ płeć i zajmowane stanowisko nie zależą od siebie,

przeciwko

$H_1 \colon$ płeć i zajmowane stanowisko są od siebie zależne.


```{r, echo=FALSE}
t2 <- structable(P~S,personel) %>% addmargins()
t1 <- ftable(personel$P,personel$S)
test2 <- fisher.test(t1)
```

```{=latex}
\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|}
  \hline
 & K & M \\ 
  \hline
NIE & 63.00 & 110.00 \\ 
\hline
  TAK & 8.00 & 19.00 \\ 
   \hline
\end{tabular}
\caption{Tablica dwudzielcza.}
\end{table}
```


**Wnioski**

Na zadanym poziomie istotności, $\alpha = 0.05$, wyliczona p-wartość wynosi `r test2$p.value` co sugeruje, że nie ma podstaw do odrzucenia hipotezy zerowej. Zatem można przyjąć, że prawdopodobieństwo, że na stanowisku kierowniczym pracuje kobieta jest równe prawdopodobieństwu, że na stanowisku kierowniczym pracuje mężczyzna.


# Zadanie 3

Korzystając z testu Freemana-Haltona, na poziomie istotności $\alpha = 0.05$, zweryfikowano następujące hipotezy:

* $H_0 \colon$ Zajmowanie stanowiska kierowniczego nie zależy od wieku.

```{=latex}
\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|}
  \hline
 & NIE & TAK \\ 
  \hline
< 25 & 23 & 3 \\ 
\hline
  26-35 & 91 & 13 \\ 
   \hline
36-50 & 39 & 6 \\ 
   \hline
> 50 & 20 & 5 \\ 
   \hline
\end{tabular}
\caption{Tablica dwudzielcza dla stanowiska oraz wieku.}
\end{table}
```

```{r, echo=FALSE}
t3a <- ftable(personel,col.vars='S',row.vars='Wiek')
```

\setlength{\leftskip}{0.5cm}
W przeprowadzonym teście p-wartość wyniosła `r fisher.test(t3a)$p.value`.


* $H_0 \colon$ Zajmowanie stanowiska kierowniczego nie zależy od wykształcenia.

```{=latex}
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
  \hline
 & NIE & TAK \\ 
  \hline
Zawodowe & 40 & 1 \\ 
\hline
Średnie & 123 & 17 \\ 
   \hline
Wyższe & 10 & 9 \\ 
   \hline
\end{tabular}
\caption{Tablica dwudzielcza dla stanowiska oraz wykształcenia.}
\end{table}
```

```{r, echo=FALSE}
t3b <- ftable(personel,col.vars='S',row.vars='Wyk')
```


>W przeprowadzonym teście p-wartość wyniosła `r fisher.test(t3b)$p.value`.

**Wnioski**

W pierwszym przeprowadzonym teście wyliczona p-wartość sugeruje, że nie ma podstaw do odrzucenia hipotezy zerowej, iż zajmowanie stanowiska kierowniczego nie zależy od wieku. Natomiast w 2. przypadku odrzucono hipotezę zerową - zajmowanie stanowiska kierowniczego nie zależy od wykształcenia.


# zadanie 4

Korzystając z testu Freemana-Haltona, na poziomie istotności $\alpha = 0.05$, zweryfikowano następujące hipotezy:

* $H_0 \colon$ Zadowolenie z wynagrodzenia (w pierwszym badanym okresie) nie zależy od zajmowanego stanowiska.

```{=latex}
\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
  \hline
 & -2 & -1 & 1 & 2\\ 
  \hline
NIE & 64 & 18 & 0 & 91 \\ 
\hline
TAK & 10 & 2 & 2 & 13 \\ 
   \hline
\end{tabular}
\caption{Tablica dwudzielcza dla zadowolenia z wynagrodzenia oraz stanowiska.}
\end{table}
```

```{r, echo=FALSE}
t4a <- ftable(personel,col.vars='W1',row.vars='S')
```


>**Wnioski**


>W przeprowadzonym teście p-wartość wyniosła `r fisher.test(t4a)$p.value`. Zatem hipotezę, że zadowolenie z wynagrodzenia nie zależy od zajmowanego stanowiska należy odrzucić.
\setlength{\leftskip}{0pt}

* $H_0 \colon$ Zadowolenie z wynagrodzenia (w pierwszym badanym okresie) nie zależy od wykształcenia.

```{=latex}
\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
  \hline
 & -2 & -1 & 1 & 2\\ 
  \hline
Zawodowe & 20 & 3 & 0 & 18 \\ 
\hline
Średnie & 45 & 17 & 0 & 78 \\ 
   \hline
Wyższe & 9 & 0 & 2 & 8 \\ 
   \hline
\end{tabular}
\caption{Tablica dwudzielcza dla zadowolenia z wynagrodzenia oraz wykształcenia.}
\end{table}
```

```{r, echo=FALSE}
t4b <- ftable(personel,col.vars='W1',row.vars='Wyk')
```

>**Wnioski**

>W przeprowadzonym teście p-wartość wyniosła `r fisher.test(t4b)$p.value`. Na tej podstawie odrzucono hipotezę o niezależności zadowolenia z wynagrodzenia od wykształcenia.

* $H_0 \colon$ Zadowolenie z wynagrodzenia(w pierwszym badanym okresie) nie zależy od płci.

```{=latex}
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|}
  \hline
 & -2 & -1 & 1 & 2\\ 
  \hline
K & 25 & 10 & 1 & 35 \\ 
\hline
M & 49 & 10 & 1 & 69 \\ 
   \hline
\end{tabular}
\caption{Tablica dwudzielcza dla zadowolenia z wynagrodzenia oraz płci.}
\end{table}
```

```{r, echo=FALSE}
t4c <- ftable(personel,col.vars='W1',row.vars='P')
```

>**Wnioski**

>Na podstawie otrzymanej p-wartości (`r fisher.test(t4c)$p.value`) nie ma podstaw do odrzucenia hipotezy o niezależności zadowolenia z wynagrodzenia od płci. 

* $H_0 \colon$ Zadowolenie z wynagrodzenia (w pierwszym badanym okresie) nie zależy od wieku. 

```{=latex}
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|}
  \hline
 & -2 & -1 & 1 & 2\\ 
  \hline
< 25 & 9 & 1 & 0 & 16 \\ 
\hline
26-35 & 42 & 9 & 1 & 52 \\ 
   \hline
36-50 & 12 & 6 & 0 & 27 \\ 
   \hline
> 50 & 11 & 4 & 1 & 9 \\ 
   \hline
\end{tabular}
\caption{Tablica dwudzielcza dla zadowolenia z wynagrodzenia oraz wieku.}
\end{table}
```

```{r, echo=FALSE}
t4d <- ftable(personel,col.vars='W1',row.vars='Wiek')
```

>**Wnioski**

>Bazując na p-wartość, która wyniosła `r fisher.test(t4d, workspace = 271020)$p.value` nie ma podstaw do odrzucenia hipotezy o niezależności zadowolenia z wynagrodzenia od wieku.

# Zadanie 6

Korzystając z testu chi-kwadrat Pearsona i z testu chi-kwadrat ilorazu wiarogodności na poziomie istotności $\alpha = 0.01$ zweryfikowano następującą hipotezę

$H_0 \colon$ Zadowolenie z wynagrodzenia nie zależy od zajmowanego stanowiska.

```{=latex}
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
  \hline
 & 0 & 1\\ 
  \hline
1 & 64 & 10 \\ 
\hline
2 & 18 & 2 \\ 
   \hline
3 & 0 & 2 \\ 
   \hline
4 & 91 & 13 \\ 
   \hline
\end{tabular}
\caption{Tablica dwudzielcza dla zadowolenia z wynagrodzenia oraz zajmowanego stanowiska.}
\end{table}
```


```{r, echo=FALSE}
chisq = chisq.test(ftable(personel$W1,personel$S)) 
likelihood = assocstats(ftable(personel$W1,personel$S))$chisq_tests[,3][1] 

data.frame('test' = c('chi-kwadrat Pearsona', 'chi-kwadratilorazu wiarogodności'),
           'p-wartość' = c(chisq$p.value, unname(likelihood))) %>% 
  kable(caption = 'P-wartości dla poszczególnych testów.') %>%
  column_spec(1, border_left = TRUE) %>%
  column_spec(2, border_right = TRUE) %>%
  kable_styling(latex_options = "HOLD_position")
```

**Wnioski**

P-wartość przeprowadzonego testu chi-kwadrat Pearsona wynosi `r chisq.test(ftable(personel$W1,personel$S))$p.value`, co oznacza, że hipotezę zerową na poziomie ufności $0.01$ należy odrzucić. Natomiast p-wartość testu chi-kwadratu ilorazu wiarygodności jest równa 0.03968965 co oznacza, że nie ma podstaw do odrzucenia hipotezy zerowej na rzecz alternatywnej. 

W zadaniu 4a, przeprowadzając test Freemana-Haltona, odrzucono na poziomie istotności $0.05$ tę samą hipotezę, którą badano w zadaniu 6. 

Zatem wyniki testu Freemana-Haltona na poziomie istotności $0.05$, jak i testu chi-kwadrat Pearsona dla $\alpha = 0.01$ sugerują, żeby odrzucić niezależność zadowolenia z wynagrodzenia i stanowiska zajmowanego przez pracownika, natomiast w przypadku testu chi-kwadrat ilorazu wiarygodności na poziomie $0.01$ nie ma podstaw do odrzucenia hipotezy. 

# Zadanie 7

W celu oszacowania zarówno rozmiaru jak i mocy testu odpowiednio dla testu Fishera, testu chi-kwadrat Pearsona oraz testu ilorazu wiarogodności przeprowadzone zostały symulacje Monte Carlo z liczbą powtórzeń $M=5000$. Wszystkie testy zostały przeprowadzone na poziomie istotności $\alpha = 0.05$. Wymienione powyżej testy weryfikują hipotezę o niezależności

$H_0 \colon$ $\boldsymbol p \in \mathcal{P}_0$, gdzie $\quad \mathcal{P}_0 = \{\boldsymbol p = (p_{11}, \dots, p_{1C},\dots, p_{RC}): p_{ij} = p_{i+} p_{+j}\}$.

Funkcja, z której skorzystano do oszacowania rozmiarów i mocy testów: 

```{r}

simulation <- function(p, alpha=0.05, M=5000){
  ns <- c(50, 100, 1000)
  fisher <- rep(NA, 3)
  chisq <- rep(NA, 3)
  ratio <- rep(NA, 3)
  for(i in 1:length(ns)){
    n <- ns[i]
    count_f <- 0
    count_c <- 0
    count_r <- 0
    for(m in 1:M){
      tab <- matrix(rmultinom(1, n, p), nrow=2)
      while(0 %in% tab){
        tab <- matrix(rmultinom(1, n, p), nrow=2)
      }
      if(fisher.test(tab, conf.level = 1-alpha)$p.value < alpha){
        count_f <- count_f + 1
      }
      if(chisq.test(tab)$p.value < alpha){
        count_c <- count_c + 1
      }
      if(assocstats(tab)$chisq_tests[,3][1] < alpha){
        count_r <- count_r + 1
      }
    }
    fisher[i] <- count_f/M
    chisq[i] <- count_c/M
    ratio[i] <- count_r/M
  }
  return(data.frame('n' = ns, 'fisher' = fisher,'chisq' = chisq, 'likelihood_ratio' = ratio))
}
```


## a) Szacowanie rozmiaru testu

W poniższych symulacjach wektor prawdopodobieństw w rozkładzie wielomianowym jest postaci $p = \bigl(\frac{1}{20}, \frac{9}{20}, \frac{1}{20}, \frac{9}{20} \bigr)$. Wektor ten można zapisać w postaci tablicy 2x2 wraz z prawdopodobieństwami brzegowymi.

```{r, echo = FALSE}
data.frame('1' = c(1/20, 1/20, 1/10), '2' = c(9/20, 9/20, 9/10), 'i+' = c(1/2, 1/2, 1), row.names = c('1', '2', '+j')) %>% kable(col.names = c('1', '2', 'i+')) %>%
  column_spec(1, border_left = TRUE) %>%
  column_spec(4, border_right = TRUE) %>%
  kable_styling(latex_options = "HOLD_position")
```

W celu weryfikacji zgodności powyższego wektora z hipotezą zerową sprawdzono, czy warunek $p_{ij} = p_{i+} p_{+j}$ jest spełniony dla każdego $i,j$ z zadanego wektora.

* $p_{11} = 0.05 \quad = \quad p_{1+}p_{+1} = 0.5 \cdot 0.10 = 0.05$
* $p_{12} = 0.45 \quad = \quad p_{1+}p_{+2} = 0.5 \cdot 0.90 = 0.45$
* $p_{21} = 0.05 \quad = \quad p_{2+}p_{+1} = 0.5 \cdot 0.10 = 0.05$
* $p_{22} = 0.45 \quad = \quad p_{2+}p_{+2} = 0.5 \cdot 0.90 = 0.45$

Zatem podany wektor prawdopodobieństw jest zgodny z hipotezą zerową.

```{r, echo = FALSE}
p <- c(1/20, 9/20, 1/20, 9/20)
#write.csv(simulation(p), 'size.csv', row.names = FALSE)
```


```{r, echo = FALSE}
read.csv('data//size.csv') %>% kable(col.names = c('n', 'test Fishera', 'test chi-kwadrat Pearsona', 'test ilorazu wiarogodności'), caption = 'Prawdopodobieństwo popełnienie błędu I rodzaju w zależności od rozmiaru próby.') %>%
  column_spec(1, border_left = TRUE) %>%
  column_spec(4, border_right = TRUE) %>%
  kable_styling(latex_options = "HOLD_position")
```

**Wnioski**

Prawdopodobieństwo popełnienia błędu I rodzaju zbliżone do $\alpha = 0.05$ dla testu Fishera oraz testu chi-kwadrat Pearsona otrzymano dopiero dla próby rozmiaru 1000. Natomiast w przypadku testu ilorazu wiarogodności zbliżony wynik osiągnięto już w przypadku $n=100$, a dla $n=1000$ poziom 0.05 został nieznacznie przekroczony. Dla $n=50$ żaden z testów nie zbliżył się do wartości $\alpha$. Ostatecznie można stwierdzić, że test Fishera oraz test chi-kwadrat Pearsona dla n = 1000 oraz test ilorazu wiarygodności dla $n \geq 100$ są testami na poziomie istotności $\alpha$,


## b) Szacowanie mocy testu

W poniższych symulacjach wektor prawdopodobieństw w rozkładzie wielomianowym jest postaci $p = \bigl(\frac{1}{40}, \frac{19}{40}, \frac{3}{40}, \frac{17}{40} \bigr)$. Ponownie wektor ten można zapisać w postaci tablicy 2x2 wraz z prawdopodobieństwami brzegowymi.

```{r, echo = FALSE}
data.frame('1' = c(1/40, 3/40, 4/40), '2' = c(19/40, 17/40, 36/40), 'i+' = c(1/2, 1/2, 1), row.names = c('1', '2', '+j')) %>% kable(col.names = c('1', '2', 'i+')) %>%
  column_spec(1, border_left = TRUE) %>%
  column_spec(4, border_right = TRUE) %>%
  kable_styling(latex_options = "HOLD_position")
```

W celu weryfikacji zgodności powyższego wektora z hipotezą zerową sprawdzono, czy warunek $p_{ij} = p_{i+} p_{+j}$ jest spełniony dla każdego $i,j$ z zadanego wektora.

* $p_{11} = 0.025 \quad \neq \quad p_{1+}p_{+1} = 0.5 \cdot 0.10 = 0.05$

Zatem podany wektor prawdopodobieństw nie jest zgodny z hipotezą zerową.


```{r, echo = FALSE}
p2 <- c(1/40, 19/40, 3/40, 17/40)
#write.csv(simulation(p2), 'power.csv', row.names = FALSE)
```


```{r, echo = FALSE}
read.csv('data//power.csv') %>% kable(col.names = c('n', 'test Fishera', 'test chi-kwadrat Pearsona', 'test ilorazu wiarogodności'), caption = 'Moc testu w zależności od wielkości próby.') %>%
  column_spec(1, border_left = TRUE) %>%
  column_spec(4, border_right = TRUE) %>%
  kable_styling(latex_options = "HOLD_position")
```

**Wnioski**

Największe prawdopodobieństwo odrzucenia hipotezy zerowej, gdy jest ona fałszywa dla każdej z testowanych długości próby odnotowano dla testu ilorazu wiarogodności. Zatem można wnioskować, że spośród badanych testów test ten ma największą moc i powinniśmy go stosować. 

# Zadanie 8

Dla odpowiednich tabel dwudzielczych wyznaczono miary współzmienności.

* zadowolenie z wynagrodzenia (w pierwszym badanym okresie) i zajmowane stanowisko

```{r, echo=FALSE}
t8a <- structable(W1~S,personel)
t8b <- structable(W1~Wyk,personel)
t8c <- structable(S~Wyk,personel)

t8a %>% addmargins() %>% 
  kable(caption='Tablica dwudzielcza dla zmiennej W1 oraz S.') %>%
  column_spec(1, border_left = TRUE) %>%
  column_spec(6, border_right = TRUE) %>%
  kable_styling(latex_options = "HOLD_position")

tau_a_col <- GoodmanKruskalTau(t8a, direction="column")
tau_a_row <- GoodmanKruskalTau(t8a, direction="row")
tau_a <- (tau_a_col + tau_a_row)/2
```

>Dla powyższej tabeli przeprowadzono test Fishera na poziomie istotności $\alpha=0.05$, w celu sprawdzenia hipotezy o niezależności. Na podstawie otrzymanej p-wartości (`r round(fisher.test(t8a)$p.value,4)`) odrzucono hipotezę o niezależności. Ponieważ zmienna S jest nominalna to do wyliczenia miary współzmienności wykorzystano współczynnik $\tau$ (współczynnik Goodmana i Kruskala), którego wartość wyniosła `r tau_a`. Z własności $\tau \colon \tau = 0$, gdy badane zmienne losowe są niezależne. Zatem można uznać, że zmienne nie są niezależne, gdyż obliczone $\tau \neq 0$. 

* zadowolenie z wynagrodzenia (w pierwszym badanym okresie) i wykształcenie

```{r, echo=FALSE}
t8b %>% addmargins() %>% 
  kable(caption='Tablica dwudzielcza dla zmiennej W1 oraz Wyk.') %>%
  column_spec(1, border_left = TRUE) %>%
  column_spec(6, border_right = TRUE) %>%
  kable_styling(latex_options = "HOLD_position")

gamma_b <- GoodmanKruskalGamma(t8b)
```

>Dla powyższej tabeli przeprowadzono test Fishera na poziomie istotności $\alpha=0.5$, w celu sprawdzenia hipotezy o niezależności. Na podstawie otrzymanej p-wartości (`r round(fisher.test(t8b)$p.value,4)`) odrzucono hipotezę o niezależności. Ponieważ obie zmienne są porządkowe do wyliczenia miary współzmienności wykorzystano współczynnik $\gamma$, którego wartość wyniosła `r gamma_b`. Zatem można uznać, że zmienne są ze sobą dodatnio zależne.

* zajmowane stanowisko i wykształcenie

```{r, echo=FALSE}
t8c %>% addmargins() %>% 
  kable(caption='Tablica dwudzielcza dla zmiennej S oraz Wyk.') %>%
  column_spec(1, border_left = TRUE) %>%
  column_spec(4, border_right = TRUE) %>%
  kable_styling(latex_options = "HOLD_position")

tau_c_col <- GoodmanKruskalTau(t8c, direction="column")
tau_c_row <- GoodmanKruskalTau(t8c, direction="row")
tau_c <- (tau_c_col + tau_c_row)/2
```

>Dla powyższej tabeli przeprowadzono test Fishera na poziomie istotności $\alpha=0.5$, w celu sprawdzenia hipotezy o niezależności. Na podstawie otrzymanej p-wartości (`r round(fisher.test(t8c)$p.value,4)`) odrzucono hipotezę o niezależności. Ponieważ zmienna S jest nominalna to do wyliczenia miary współzmienności wykorzystano współczynnik $\tau$ (współczynnik Goodmana i Kruskala), którego wartość wyniosła `r tau_c`. Zatem można uznać, że zmienne nie są niezależne, gdyż obliczone $\tau \neq 0$. 


# Zadanie 9
```{r}
tabela <- as.matrix(ftable(personel$Wyk, personel$W1))

analiza.korespondencji <- function(tabela){
  n <- length(tabela[,1])
  m <- length(tabela[1,])
  n <- sum(rowSums(tabela))
  P <- tabela/n
  r <- rowSums(P)
  c <- colSums(P)
  d_r <- diag(r)
  d_c <- diag(c)
  R <- inv(d_r)
  C <- inv(d_c)
  A <- inv(d_r ^ (1/2)) %*% (P - r %*% t(c)) %*% inv(d_c ^ (1/2))
  total_inertia <- tr(t(A) %*% A)
  A <- svd(A)
  Gamma <- diag(A$d)
  U <- A$u
  V <- A$v
  F_ <- inv(d_r^(1/2)) %*% U %*% Gamma
  G <- inv(d_c^(1/2)) %*% V %*% Gamma
  F_ <- F_[,1:2]
  G <- G[,1:2]
  xs_row <- F_[,1] #współrzędne x dla wierszy
  ys_row <- F_[,2] #współrzędne y dla wierszy
  xs_col <- G[,1] #współrzędne x dla kolumn
  ys_col <- G[,2] #współrzędne y dla kolumn
  gam <- A$d ^ 2
  dim1 <- round(sum(gam[1])/sum(gam), 3) * 100
  dim2 <- round(sum(gam[2])/sum(gam), 3) * 100
  df_row <- data.frame('Dim.1' = xs_row, 'Dim.2' = ys_row, row.names = rownames(tabela))
  df_col <- data.frame('Dim.1' = xs_col, 'Dim.2' = ys_col, row.names = colnames(tabela))
  
  ggplot() + geom_point(aes(x=df_row$Dim.1, y=df_row$Dim.2), color='blue', shape = 16) +
    geom_text(aes(x=df_row$Dim.1, y=df_row$Dim.2),label=rownames(df_row), 
              nudge_x = 0, nudge_y = 0.02, size=2.5, color='blue') +
    geom_point(aes(x=df_col$Dim.1, y=df_col$Dim.2), color='red', shape=17) +
    geom_text(aes(x=df_col$Dim.1, y=df_col$Dim.2),label=rownames(df_col), 
              nudge_x = 0, nudge_y = -0.02, size=2.5, color='red') +
    xlab(paste('Dim 1 (', as.character(round(dim1,2)), '%)')) +
    ylab(paste('Dim 2 (', as.character(round(dim2,2)), '%)'))
}
```

# Zadanie 10

Przeprowadzono analizę korespondencji dla zadowolenia z wynagrodzenia w pierwszym badanym okresie i zajmowanego stanowiska przy pomocy funkcji wbudowanej oraz własnej funkcji.

```{r wlasna, echo=FALSE, fig.cap="Wykres korespondencji dla zadowolenia z wynagrodzenia w pierwszym okresie i wykształcenia uzyskany za pomocą funkcji wbudowanej."}
analiza.korespondencji(tabela)
```

```{r wbudowana, echo=FALSE, fig.cap="Wykres korespondencji dla zadowolenia z wynagrodzenia w pierwszym okresie i wykształcenia, wykonany za pomocą funkcji wbudowanej z biblioteki 'ca'."}
plot(ca(tabela))
```

**Wnioski** 

Wyniki analizy korespondencji uzyskane przy pomocy funkcji wbudowanej (Wykres 1.) są identyczne jak w przypadku funkcji wbudowanej (Wykres 2.), więc można wywnioskować, że funkcja została zaimplementowana poprawnie. 

