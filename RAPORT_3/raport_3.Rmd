---
title: "Raport nr 3"
author: "Natalia Iwańska 262270, Klaudia Janicka 262268"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
knitr::opts_chunk$set(fig.width=8, fig.height=4.5) 
pdf.options(encoding = 'CP1250')
```

```{r, include=FALSE, echo=FALSE}
library("tidyverse")
library('ascii')
library("vcd")
library("ggplot2")
library("knitr")
library("dplyr")
library("xtable")
library("kableExtra")
library("ggplot2")
library("gnm")
```


```{r, include=FALSE, echo=FALSE}
personel <- read.csv2('personel.csv',header=FALSE)
names(personel) <- c('D','S','A1','A2','W1','W2','P','Wiek','Wyk')
personel$A2[personel$A2 == '11'] = '1'
personel <- personel %>% mutate(across(D:Wyk,as.factor))
personel$A2 <- factor(personel$A2, levels = c(-2,-1,0,1,2))

```


# Zadanie 1

```{r, echo=FALSE}
tab1 <- ftable(personel$A1, personel$A2)
tab1 %>% addmargins() %>% kable(caption='Tablica dwudzielcza dla zmniennych A1 i A2.', col.names=c(-2,-2,0,1,2,'Sum')) %>% 
  column_spec(1, border_left = TRUE) %>%
  column_spec(7, border_right = TRUE) %>%
  kable_styling(latex_options = "HOLD_position")
  
```
## Test McNemary
Nie możemy skorzystać z testu McNemary, ponieważ w tablicy na odpowiadjących sobie miejscach ($Y_{ij}$ i $Y_{ji}$) występują zera, co "psuje" nam statystykę testową (wynika to wprost z jej definicji).


## Test bazujący na ilorazie wiarogodności

```{r, echo=FALSE}
data1 <- tab1 %>% data.frame()
symetry <- glm(Freq~Symm(Var1,Var2), data=data1, family = poisson)
stat <- symetry$deviance
df <- symetry$df.residual
p_val <- 1- pchisq(stat, df)
```

Korzystając z testu bazującego na ilorazie wiarogodności na poziomie istotności $\alpha=0.05$ otrzymana p-wartość wyniosła `r p_val`. Zatem weryfikowaną hipotezę o symetrii, która jest równoważna hipotezie o brzegowej jednorodności należy odrzucić.


# Zadanie 2

```{r, echo=FALSE}
tab2 <- ftable(personel$W1, personel$W2)
tab2 %>% addmargins() %>% 
  kable(caption='Tablica dwudzielcza dla zmniennych W1 i W2.', col.names = c(-2, -1, 1, 2, 'Sum')) %>% 
  column_spec(1, border_left = TRUE) %>%
  column_spec(6, border_right = TRUE) %>%
  kable_styling(latex_options = "HOLD_position")
```
## Test McNemary
Podobnie jak w poprzednim zadaniu nie możemy skorzystać z testu McNemary, ponieważ w tablicy na odpowiadających sobie miejscach ($Y_{ij}$ i $Y_{ji}$) występują zera, co "psuje" nam statystykę testową (wynika to wprost z jej definicji).

## Test bazujący na ilorazie wiarogodności

```{r, echo=FALSE}
data2 <- tab2 %>% data.frame()
symetry2 <- glm(Freq~Symm(Var1,Var2), data=data2, family = poisson)
stat2 <- symetry2$deviance
df2 <- symetry2$df.residual
p_val2 <- 1- pchisq(stat2, df2)
```

Korzystając z testu bazującego na ilorazie wiarogodności na poziomie istotności $\alpha=0.05$ otrzymana p-wartość wyniosła `r p_val2`. Zatem nie mamy podstaw do odrzucenia hipotezy zerowej o symetrii, która jest równoważna hipotezie o brzegowej jednorodności.


# Zadanie 3
```{r, echo=FALSE}
W1 <- ((personel$W1 %>% as.numeric() > 2) %>% as.numeric() * 2 - 1 ) %>% as.factor()
W2 <- ((personel$W2 %>% as.numeric() > 2) %>% as.numeric() * 2 - 1 ) %>% as.factor()
tabela <- ftable(W1, W2)
tabela
```

```{r}
#TEST Z
test_z <- function(tabela){
  n <- sum(rowSums(tabela))
  P <- tabela/n
  r <- rowSums(P)
  c <- colSums(P)
  D <- r[1] - c[1]
  sigma2_D <- (r[1]*(1-r[1])+c[1]*(1-c[1])-2*(P[1,1]*P[2,2]-P[1,2]*P[2,1]))/n
  Z <- D/sqrt(sigma2_D)
  p <- 2*(1 - pnorm(abs(Z)))
  return(p)
}

#TEST Z0
test_z0 <- function(tabela){
  n <- sum(rowSums(tabela))
  P <- tabela/n
  r <- rowSums(P)
  c <- colSums(P)
  D <- r[1] - c[1]
  sigma2_D0 <- (tabela[1,2]+tabela[2,1])/n^2
  Z_0 <- D/sqrt(sigma2_D0)
  p <- 2*(1 - pnorm(abs(Z_0)))
  return(p)
}
```


```{r, echo=FALSE}
df <- data.frame('test' = c('Test Z', 'Test Z0', 'McNemar test z poprawką na ciągłość', 
                            'McNemar test bez poprawki'), 'p-value' = c(test_z(tabela), test_z0(tabela), mcnemar.test(tabela)$p.value, mcnemar.test(tabela, correct=FALSE)$p.value))
df %>% kable(col.names = c('test', 'p-value')) %>%
  column_spec(1, border_left = TRUE) %>%
  column_spec(2, border_right = TRUE) %>%
  kable_styling(latex_options = "HOLD_position")
```
Na podstawie otrzymanych p-wartości testów przeprowadzonych na poziomie istotności $\alpha=0.05$ stwierdzamy, że nie mamy podstaw do odrzucenia hipotezy zerowej o symetrii, która jest równoważna hipotezie o brzegowej jednorodności.

# Zadanie 4

```{r}
moc <- function(n, test){
  MC <- 1000
  p2 <- seq(0.01,0.99,0.01)
  p1 <- 0.5
  m <- length(p2)
  res <- rep(NA, m)
  for (i in 1:m){
    counter <- 0
    for (j in 1:MC){
    X <- factor(sample(c("1","0"), n, replace=TRUE, prob = c(p1,1-p1)), levels = 0:1)
    Y <- factor(sample(c("1","0"), n, replace=TRUE, prob = c(p2[i],1-p2[i])), levels=0:1)
    tab <- ftable(X,Y)
    if (test(tab) < 0.05){
      counter <- counter+1
      }
    }
    res[i] <- counter/MC
  }
return(data.frame( 'prob' = p2, 'results' = res))
}
```


```{r, echo=FALSE, fig.cap='Wykres funkcji mocy testu $Z$ i $Z_0$ dla $n=20$'}
moc_20 <- as.data.frame(read.csv('moc_20.csv'))
moc0_20 <- as.data.frame(read.csv('moc0_20.csv'))

ggplot() + geom_line(data=moc_20,aes(x=prob, y=results, colour = 'Z')) + geom_line(data=moc0_20,aes(x=prob, y=results, color='Z0')) + scale_colour_manual("Test", 
                      breaks = c("Z", "Z0"),
                      values = c("black", "red")) + geom_hline(yintercept=0.05, color='grey50')+ labs(x='Wartość p2', y='Moc testu')
```

```{r, echo=FALSE, fig.cap='Wykres funkcji mocy testu $Z$ i $Z_0$ dla $n=50$'}
moc_50 <- as.data.frame(read.csv('moc_50.csv'))
moc0_50 <- as.data.frame(read.csv('moc0_50.csv'))

ggplot() + geom_line(data=moc_50,aes(x=prob, y=results, colour = 'Z')) + geom_line(data=moc0_50,aes(x=prob, y=results, color='Z0')) + scale_colour_manual("Test", 
                      breaks = c("Z", "Z0"),
                      values = c("black", "red"))+ geom_hline(yintercept=0.05, color='grey50') + labs(x='Wartość p2', y='Moc testu')
```

```{r, echo=FALSE, fig.cap='Wykres funkcji mocy testu $Z$ i $Z_0$ dla $n=100$'}
moc_100 <- as.data.frame(read.csv('moc_100.csv'))
moc0_100 <- as.data.frame(read.csv('moc0_100.csv'))

ggplot() + geom_line(data=moc_100,aes(x=prob, y=results, colour = 'Z')) + geom_line(data=moc0_100,aes(x=prob, y=results, color='Z0')) + scale_colour_manual("Test", 
                      breaks = c("Z", "Z0"),
                      values = c("black", "red"))+ geom_hline(yintercept=0.05, color='grey50')+ labs(x='Wartość p2', y='Moc testu')
```

```{r, echo=FALSE, fig.cap='Wykres funkcji mocy testu $Z$ i $Z_0$ dla $n=1000$'}
moc_1000 <- as.data.frame(read.csv('moc_1000.csv'))
moc0_1000 <- as.data.frame(read.csv('moc0_1000.csv'))

ggplot() + geom_line(data=moc_1000,aes(x=prob, y=results, colour = 'Z')) + geom_line(data=moc0_1000,aes(x=prob, y=results, color='Z0')) + scale_colour_manual("Test", 
                      breaks = c("Z", "Z0"),
                      values = c("black", "red"))+ geom_hline(yintercept=0.05, color='grey50')+ labs(x='Wartość p2', y='Moc testu')
```
* Wnioski 

Na wykresach powyżej przedstawiliśmy moce testów $Z$ i $Z_0$ dla $n\in\{20, 50, 100, 1000\}$, na podstawie symulacji Monte Carlo. Szarą linią na wykresach oznaczono poziom istotności $\alpha = 0.05$. Funkcja mocy testu powinna przechodzić przez wartość poziomu istotności w puncie $p_2=0.5$, ponieważ jest to miejsce, w którym oba prawdopodobieństwa są takie same, a wtedy hipoteza zerowa powinna być przyjmowana z prawdopodobieństwem $1-\alpha$. Dla $n=20$ funkcja mocy dla testu $Z$ jest lekko powyżej oczekiwanej wartości, ale wraz ze zwiększaniem się $n$, funkcja coraz bardziej zbliża się do pożądanej wartości. Można na tej podstawie wyciągnąć wniosek, że test $Z$ jest testem asymptotycznie nieobciążonym. Dla testu $Z_0$ sytuacja jest podobna, jednak wartość funkcji mocy dla najmniejszego rozważanego $n$, dla $p_2=0.5$ jest trochę mniejsza niż założony poziom istotności $\alpha$, ale znów, ze wzrostem wartości $n$, zbliża się ona do poziomu istotności, więc podobnie jak przy teście $Z$, można wyciągnąć wniosek, że test $Z_0$ jest testem asymptotycznie nieobciążonym. Natomiast obciążenie obydwu testów dla małych $n$ nie jest duża. Dla zwiększających się wartości $n$ widzimy, że wartości funkcji mocy są większe, dla $p_2\neq0.5$. Było to do przewidzenia, ponieważ wraz ze wzrastającą liczbą prób (ankietowanych), test powinien być częściej odrzucany dla $p_1\neq p_2$, bo moc testu rośnie.




# Zadanie 5
Przyjmujemy za zmienną $1$ zmienną $S$ (zajmowane stanowisko), za zmienną $2$ – zmienną $W1$ (zadowolenie z wynagrodzenia w pierwszym badanym okresie) i za zmienną $3$ – zmienną $Wyk$.

* $[1\:3]$ zmienne ,,S'' i ,,Wyk'' mają dowolne rozkłady oraz zmienne te są niezależne, a zmienna ,,W1'' ma rozkład równomierny

```{r, echo=FALSE}
df <- as.data.frame(ftable(personel$S,personel$W1,personel$Wyk))
names(df) <- c('S', 'W1', 'Wyk', 'Freq')
```

```{r}
model_a <- glm(Freq ~ S + Wyk, 
               data = df, family = poisson)
p_a <- 1-pchisq(deviance(model_a), df = df.residual(model_a))
cbind(model_a$data, fitted = fitted(model_a))%>% kable(caption = "Porównanie wyznaczonych liczności na podstawie modelów z rzeczywistymi licznościami danych", label = "Table5")
```

> P-wartość `r p_a` jest mniejsza niż założony poziom istotności $\alpha$, więc odrzucamy hipotezę zerową. Nasze dane nie pochodzą z modelu $[1\:3]$.

* $[13]$ zmienne ,,S'' i ,,Wyk'' mają dowolne rozkłady oraz zmienne te nie są niezależne, a zmienna ,,W1'' ma rozkład równomierny
```{r}
model_b <- glm(Freq ~ S + Wyk + S*Wyk, 
               data = df, family = poisson)
p_b <- 1-pchisq(deviance(model_b), df = df.residual(model_b))
cbind(model_b$data, fitted = fitted(model_b))%>% kable(caption = "Porównanie wyznaczonych liczności na podstawie modelów z rzeczywistymi licznościami danych", label = "Table6")
```
> P-wartość `r p_b` jest mniejsza niż założony poziom istotności $\alpha$, więc odrzucamy hipotezę zerową. Nasze dane nie pochodzą z modelu $[13]$.

* $[1\:2\:3]$ zmienne ,,S'', ,,W1'' i ''Wyk'' są wzajemnie niezależne

```{r}
model_c <- glm(Freq ~ S + Wyk + W1, 
               data = df, family = poisson)
p_c <- 1-pchisq(deviance(model_c), df = df.residual(model_c))
cbind(model_c$data, fitted = fitted(model_c))%>% kable(caption = "Porównanie wyznaczonych liczności na podstawie modelów z rzeczywistymi licznościami danych", label = "Table7")
```
> P-wartość `r p_c` jest mniejsza niż założony poziom istotności $\alpha$, więc odrzucamy hipotezę zerową. Nasze dane nie pochodzą z modelu $[1\:2\:3]$.

* $[12 \:3]$ zmienna "Wyk" jest niezależna od zmiennych "S" i "W1", ale zmienne "S" i "W1" nie są niezależne

```{r}
model_d <- glm(Freq ~ S + Wyk + W1 + S*W1, 
               data = df, family = poisson)
p_d <- 1-pchisq(deviance(model_d), df = df.residual(model_d))
cbind(model_d$data, fitted = fitted(model_d))%>% kable(caption = "Porównanie wyznaczonych liczności na podstawie modelów z rzeczywistymi licznościami danych", label = "Table8")
```
> P-wartość `r p_d` jest mniejsza niż założony poziom istotności $\alpha$, więc odrzucamy hipotezę zerową. Nasze dane nie pochodzą z modelu $[12\:3]$.

* $[12\:13]$ przy ustalonej wartości zmiennej "S", zmienne "W1" i "Wyk" są niezależne

```{r}
model_e <- glm(Freq ~ S + Wyk + W1 + S*W1 + S*Wyk, 
               data = df, family = poisson)
p_e <- 1-pchisq(deviance(model_e), df = df.residual(model_e))
cbind(model_e$data, fitted = fitted(model_e))%>% kable(caption = "Porównanie wyznaczonych liczności na podstawie modelów z rzeczywistymi licznościami danych", label = "Table9")
```
> P-wartość `r p_e` jest większa niż założony poziom istotności $\alpha$, więc nie mamy podstaw do odrzucenia hipotezy zerowej, czyli zakładamy, że nasze dane pochodzą z modelu $[12\:13]$.

* $[1\:23]$ zmienna "S" jest niezależna od zmiennych "Wyk" i "W1", ale zmienne "Wyk" i "W1" nie są niezależne

```{r}
model_f <- glm(Freq ~ S + Wyk + W1 + W1*Wyk, 
               data = df, family = poisson)
p_f <- 1-pchisq(deviance(model_f), df = df.residual(model_f))
cbind(model_f$data, fitted = fitted(model_f))%>% kable(caption = "Porównanie wyznaczonych liczności na podstawie modelów z rzeczywistymi licznościami danych", label = "Table10")
```
> P-wartość `r p_f` jest mniejsza niż założony poziom istotności $\alpha$, więc odrzucamy hipotezę zerową. Nasze dane nie pochodzą z modelu $[1\:23]$.

\begin{table}[h]
		\begin{center}
			\begin{tabular}{|c|c|c|c|c|c|c|}
				\hline
				& \multicolumn{6}{c|}{Modele}\\\cline{2-7}
				& $[1\:3]$ & $[13]$ & $[1\:2\:3]$& $[12\:3]$ & $[12\:13]$ & $[1\:23]$ \\\hline
				P-wartość & `r 1-pchisq(deviance(model_a), df = df.residual(model_a))` & `r 1-pchisq(deviance(model_b), df = df.residual(model_b))` & `r 1-pchisq(deviance(model_c), df = df.residual(model_c))` & `r 1-pchisq(deviance(model_d), df = df.residual(model_d))` & `r 1-pchisq(deviance(model_e), df = df.residual(model_e))` & `r 1-pchisq(deviance(model_f), df = df.residual(model_f))`\\\hline
			\end{tabular}
		\end{center}
		\caption{P-wartości testów statystycznych}
		\label{tab:tabela4}
\end{table}

# Zadanie 6

Przyjmujemy za zmienną $1$ zmienną $S$ (zajmowane
stanowisko), za zmienną $2$ – zmienną $P$ (płeć) i za zmienną $3$ – zmienną $Wyk$
(wykształcenie).

* $[1\:3]$ zmienne ,,S'' i ,,Wyk'' mają dowolne rozkłady oraz zmienne te są niezależne, a zmienna ,,P'' ma rozkład równomierny

```{r, echo=FALSE}
df <- as.data.frame(ftable(personel$S,personel$P,personel$Wyk))
names(df) <- c('S', 'P', 'Wyk', 'Freq')
```

```{r}
model_a <- glm(Freq ~ S + Wyk, 
               data = df, family = poisson)
p_a <- 1-pchisq(deviance(model_a), df = df.residual(model_a))
cbind(model_a$data, fitted = fitted(model_a))%>% kable(caption = "Porównanie wyznaczonych liczności na podstawie modelów z rzeczywistymi licznościami danych", label = "Table6")
```

> P-wartość `r p_a` jest mniejsza niż założony poziom istotności $\alpha$, więc odrzucamy hipotezę zerową. Nasze dane nie pochodzą z modelu $[1\:3]$.

* $[13]$ zmienne ,,S'' i ,,Wyk'' mają dowolne rozkłady oraz zmienne te nie są niezależne, a zmienna ,,P'' ma rozkład równomierny
```{r}
model_b <- glm(Freq ~ S + Wyk + S*Wyk, 
               data = df, family = poisson)
p_b <- 1-pchisq(deviance(model_b), df = df.residual(model_b))
cbind(model_b$data, fitted = fitted(model_b))%>% kable(caption = "Porównanie wyznaczonych liczności na podstawie modelów z rzeczywistymi licznościami danych", label = "Table12")
```
> P-wartość `r p_b` jest mniejsza niż założony poziom istotności $\alpha$, więc odrzucamy hipotezę zerową. Nasze dane nie pochodzą z modelu $[13]$.

* $[1\:2\:3]$ zmienne ,,S'', ,,P'' i ''Wyk'' są wzajemnie niezależne

```{r}
model_c <- glm(Freq ~ S + Wyk + P, 
               data = df, family = poisson)
p_c <- 1-pchisq(deviance(model_c), df = df.residual(model_c))
cbind(model_c$data, fitted = fitted(model_c))%>% kable(caption = "Porównanie wyznaczonych liczności na podstawie modelów z rzeczywistymi licznościami danych", label = "Table13")
```
> P-wartość `r p_c` jest mniejsza niż założony poziom istotności $\alpha$, więc odrzucamy hipotezę zerową. Nasze dane nie pochodzą z modelu $[1\:2\:3]$.

* $[12 \:3]$ zmienna "Wyk" jest niezależna od zmiennych "S" i "P", ale zmienne "S" i "P" nie są niezależne

```{r}
model_d <- glm(Freq ~ S + Wyk + P + S*P, 
               data = df, family = poisson)
p_d <- 1-pchisq(deviance(model_d), df = df.residual(model_d))
cbind(model_d$data, fitted = fitted(model_d))%>% kable(caption = "Porównanie wyznaczonych liczności na podstawie modelów z rzeczywistymi licznościami danych", label = "Table14")
```
> P-wartość `r p_d` jest mniejsza niż założony poziom istotności $\alpha$, więc odrzucamy hipotezę zerową. Nasze dane nie pochodzą z modelu $[12\:3]$.

* $[12\:13]$ przy ustalonej wartości zmiennej "S", zmienne "P" i "Wyk" są niezależne

```{r}
model_e <- glm(Freq ~ S + Wyk + P + S*P + S*Wyk, 
               data = df, family = poisson)
p_e <- 1-pchisq(deviance(model_e), df = df.residual(model_e))
cbind(model_e$data, fitted = fitted(model_e))%>% kable(caption = "Porównanie wyznaczonych liczności na podstawie modelów z rzeczywistymi licznościami danych", label = "Table16")
```
> P-wartość `r p_e` jest mniejsza niż założony poziom istotności $\alpha$, więc odrzucamy hipotezę zerową. Nasze dane nie pochodzą z modelu $[12\:13]$.

* $[1\:23]$ zmienna "S" jest niezależna od zmiennych "Wyk" i "P", ale zmienne "Wyk" i "P" nie są niezależne

```{r}
model_f <- glm(Freq ~ S + Wyk + P + P*Wyk, 
               data = df, family = poisson)
p_f <- 1-pchisq(deviance(model_f), df = df.residual(model_f))
cbind(model_f$data, fitted = fitted(model_f))%>% kable(caption = "Porównanie wyznaczonych liczności na podstawie modelów z rzeczywistymi licznościami danych", label = "Table17")
```
> P-wartość `r p_f` jest mniejsza niż założony poziom istotności $\alpha$, więc odrzucamy hipotezę zerową. Nasze dane nie pochodzą z modelu $[1\:23]$.

\begin{table}[h!]
		\begin{center}
			\begin{tabular}{|c|c|c|c|c|c|c|}
				\hline
				& \multicolumn{6}{c|}{Modele}\\\cline{2-7}
				& $[1\:3]$ & $[13]$ & $[1\:2\:3]$& $[12\:3]$ & $[12\:13]$ & $[1\:23]$ \\\hline
				P-wartość & `r 1-pchisq(deviance(model_a), df = df.residual(model_a))` & `r 1-pchisq(deviance(model_b), df = df.residual(model_b))` & `r 1-pchisq(deviance(model_c), df = df.residual(model_c))` & `r 1-pchisq(deviance(model_d), df = df.residual(model_d))` & `r 1-pchisq(deviance(model_e), df = df.residual(model_e))` & `r 1-pchisq(deviance(model_f), df = df.residual(model_f))`\\\hline
			\end{tabular}
		\end{center}
		\caption{P-wartości testów statystycznych}
		\label{tab:tabela4}
\end{table}

# Zadanie 7

Do zmiennych $S$, $W1$ i $Wyk$ przyjmiemy model log-liniowy $[13 \: 23]$ oraz $[123]$ i na tej podstawie obliczymy prawdopodobieństwa.

* Prawdopodobieństwo, że osoba pracująca na stanowisku kierowniczym jest zdecydowanie zadowolona ze swojego wynagrodzenia. 

```{r, echo=FALSE}
df <- as.data.frame(ftable(personel$S,personel$W1,personel$Wyk))
names(df) <- c('S', 'W1', 'Wyk', 'Freq')

model1 <- glm(Freq ~ S+W1+Wyk+S*Wyk+W1*Wyk, data = df, family = poisson)
result1 <- cbind(model1$data, fitted(model1))
result1$`fitted(model1)` <- result1$`fitted(model1)`/sum(result1$`fitted(model1)`)
result1$Freq <- result1$Freq/sum(result1$Freq)

model2 <- glm(Freq ~ S+W1+Wyk+S*Wyk+W1*Wyk+S*W1+S*W1*Wyk, data = df, family = poisson)
result2 <- cbind(model2$data, fitted(model2))
result2$`fitted(model2)` <- result2$`fitted(model2)`/sum(result2$`fitted(model2)`)
result2$Freq <- result2$Freq/sum(result2$Freq)
```

Przykładowy kod obliczający to prawdopodobieństwo dla modelu $[13 \: 23]$:

```{r}
sum(result1$`fitted(model1)`[result1$S == 1 & result1$W1 == 2])/(sum(result1$`fitted(model1)`[result1$S == 1]))
```

```{r, echo=FALSE}
m1 <- sum(result1$`fitted(model1)`[result1$S == 1 & result1$W1 == 2])/(sum(result1$`fitted(model1)`[result1$S == 1]))

m2 <-  sum(result2$`fitted(model2)`[result2$S == 1 & result2$W1 == 2])/(sum(result2$`fitted(model2)`[result2$S == 1]))

emp <- sum(result1$Freq[result1$S == 1 & result1$W1 == 2])/(sum(result1$Freq[result1$S == 1]))
```

\begin{table}[H]
\centering
\begin{tabular}{lc|c|ll}
\cline{3-3}
                      &                    & Prawdopodobieństwo &                      &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & Wartość empiryczna & `r emp`               &                      &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & Model {[}13 23{]}  & `r m1`                & \multicolumn{1}{c}{} &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & Model {[}123{]}    & `r m2`                &                      &  \\ \cline{2-3}
\end{tabular}
\caption{Oszacowane prawdopodobieństwa }
\label{tab:5}
\end{table}

Na podstawie wyników przedstawionych w tabeli możemy zauważyć, że do naszych danych lepiej niż model $[13 \: 23]$ dopasował się model $[123]$ - prawdopodobieństwo obliczone z wykorzystaniem tego modelu jest identyczne jak prawdopodobieństwo empiryczne. 

* Prawdopodobieństwo, że osoba z wykształceniem zawodowym pracuje na stanowisku kierowniczym. 

```{r, echo=FALSE}
m1_1 <- sum(result1$`fitted(model1)`[result1$Wyk == 1 & result1$S == 1])/(sum(result1$`fitted(model1)`[result1$Wyk == 1]))
m2 <- sum(result2$`fitted(model2)`[result2$Wyk == 1 & result2$S == 1])/(sum(result2$`fitted(model2)`[result2$Wyk == 1]))
emp <- sum(result1$Freq[result1$S == 1 & result1$Wyk == 1])/(sum(result1$Freq[result1$Wyk == 1]))
```

\begin{table}[H]
\centering
\begin{tabular}{lc|c|ll}
\cline{3-3}
                      &                    & Prawdopodobieństwo &                      &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & Wartość empiryczna & `r emp`               &                      &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & Model {[}13 23{]}  & `r m1_1`                & \multicolumn{1}{c}{} &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & Model {[}123{]}    & `r m2`                &                      &  \\ \cline{2-3}
\end{tabular}
\caption{Oszacowane prawdopodobieństwa }
\label{tab:6}
\end{table}

Prawdopodobieństwa obliczone z wykorzystaniem obu modeli są identyczne jak prawdopodobieństwo empiryczne. Okazuje się, że prawdopodobieństwo, że osoba z wykształceniem zawodowym pracuje na na stanowisku kierowniczym jest niezwykle małe. 

* Prawdopodobieństwo, że osoba z wykształceniem wyższym nie pracuje na stanowisku kierowniczym. 

```{r, echo=FALSE}
m1 <- sum(result1$`fitted(model1)`[result1$Wyk == 3 & result1$S == 0])/(sum(result1$`fitted(model1)`[result1$Wyk == 3]))
m2 <-  sum(result2$`fitted(model2)`[result2$Wyk == 3 & result2$S == 0])/(sum(result2$`fitted(model2)`[result2$Wyk == 3]))
emp <- sum(result1$Freq[result1$S == 0 & result1$Wyk == 3])/(sum(result1$Freq[result1$Wyk == 3]))
```

\begin{table}[H]
\centering
\begin{tabular}{lc|c|ll}
\cline{3-3}
                      &                    & Prawdopodobieństwo &                      &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & Wartość empiryczna & `r emp`               &                      &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & Model {[}13 23{]}  & `r m1`                & \multicolumn{1}{c}{} &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & Model {[}123{]}    & `r m2`                &                      &  \\ \cline{2-3}
\end{tabular}
\caption{Oszacowane prawdopodobieństwa}
\label{tab:7}
\end{table}

Znów prawdopodobieństwa obliczone z wykorzystaniem modeli są identyczne jak prawdopodobieństwo empiryczne. 

# Zadanie 8
Do zmiennych $S$, $P$ i $Wyk$ przyjmiemy model log-liniowy $[13 \: 23]$ i na tej podstawie obliczymy prawdopodobieństwo.

```{r, echo=FALSE}
df <- as.data.frame(ftable(personel$S,personel$P,personel$Wyk))
names(df) <- c('S', 'P', 'Wyk', 'Freq')

model <- glm(Freq ~ S+P+Wyk+S*Wyk+P*Wyk, data = df, family = poisson)
result <- cbind(model$data, fitted(model))
result$`fitted(model)` <- result$`fitted(model)`/sum(result$`fitted(model)`)
result$Freq <- result$Freq/sum(result$Freq)
```

* Prawdopodobieństwo, że osoba pracująca na stanowisku kierowniczym jest kobietą.

Przykładowe wywołanie: 

```{r}
m <- sum(result$`fitted(model)`[result$S == 1 & result$P == 'K'])/(sum(result$`fitted(model)`[result$S == 1]))
emp <- sum(result$Freq[result$S == 1 & result$P == 'K'])/(sum(result$Freq[result$S == 1]))
```

\begin{table}[H]
\centering
\begin{tabular}{lccll}
\cline{3-3}
                      & \multicolumn{1}{c|}{}                   & \multicolumn{1}{c|}{Prawdopodobieństwo} &                      &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & \multicolumn{1}{c|}{Wartość empiryczna} & \multicolumn{1}{c|}{`r m`}                &                      &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & \multicolumn{1}{c|}{Model {[}13 23{]}}  & \multicolumn{1}{c|}{`r emp`}                & \multicolumn{1}{c}{} &  \\ \cline{2-3}
                      &                                         &                                         &                      & 
\end{tabular}
\caption{Oszacowane prawdopodobieństwa}
\label{tab:8}
\end{table}

Prawdopodobieństwo uzyskane z wykorzystaniem modelu $[13 \: 23]$ dość mocno odbiegają od otrzymanego wyniku empirycznego. 

* Prawdopodobieństwo, że osoba z wykształceniem zawodowym pracuje na stanowisku kierowniczym. 

```{r, echo=FALSE}
m <- sum(result$`fitted(model)`[result$S == 1 & result$Wyk == 1])/(sum(result$`fitted(model)`[result$Wyk == 1]))
emp <- sum(result$Freq[result$S == 1 & result$Wyk == 1])/(sum(result$Freq[result$Wyk == 1]))
```

\begin{table}[H]
\centering
\begin{tabular}{lccll}
\cline{3-3}
                      & \multicolumn{1}{c|}{}                   & \multicolumn{1}{c|}{Prawdopodobieństwo} &                      &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & \multicolumn{1}{c|}{Wartość empiryczna} & \multicolumn{1}{c|}{`r m`}                &                      &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & \multicolumn{1}{c|}{Model {[}13 23{]}}  & \multicolumn{1}{c|}{`r emp`}                & \multicolumn{1}{c}{} &  \\ \cline{2-3}
                      &                                         &                                         &                      & 
\end{tabular}
\caption{Oszacowane prawdopodobieństwa}
\label{tab:9}
\end{table}

Prawdopodobieństwo otrzymane za pomocą modelu jest identyczne jak to otrzymane z wykorzystaniem modelu. 


\begin{table}[H]
\centering
\begin{tabular}{lccll}
\cline{3-3}
                      & \multicolumn{1}{c|}{}          & \multicolumn{1}{c|}{Prawdopodobieństwo} &                      &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & \multicolumn{1}{c|}{Zadanie 7} & \multicolumn{1}{c|}{`r m1_1``}                &                      &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & \multicolumn{1}{c|}{Zadanie 8} & \multicolumn{1}{c|}{`r m`}                & \multicolumn{1}{c}{} &  \\ \cline{2-3}
                      &                                &                                         &                      & 
\end{tabular}
\caption{Porównanie prawdopodobieństw tego samego problemu uzyskanych w zadaniu 7. i 8.}
\label{tab:10}
\end{table}

Prawdopodobieństwa tego samego problemu z zadania 7. i 8. otrzymane za pomocą różnych modeli log-liniowych są identyczne. 

* Prawdopodobieństwo, że osoba z wykształceniem wyższym jest mężczyzną.

```{r, echo=FALSE}
m <- sum(result$`fitted(model)`[result$P == 'M' & result$Wyk == 3])/(sum(result$`fitted(model)`[result$Wyk == 3]))
emp <- sum(result$Freq[result$P == 'M' & result$Wyk == 3])/(sum(result$Freq[result$Wyk == 3]))
```

\begin{table}[H]
\centering
\begin{tabular}{lccll}
\cline{3-3}
                      & \multicolumn{1}{c|}{}                   & \multicolumn{1}{c|}{Prawdopodobieństwo} &                      &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & \multicolumn{1}{c|}{Wartość empiryczna} & \multicolumn{1}{c|}{`r m`}                &                      &  \\ \cline{2-3}
\multicolumn{1}{l|}{} & \multicolumn{1}{c|}{Model {[}13 23{]}}  & \multicolumn{1}{c|}{`r emp`}                & \multicolumn{1}{c}{} &  \\ \cline{2-3}
                      &                                         &                                         &                      & 
\end{tabular}
\caption{Oszacowane prawdopodobieństwa}
\label{tab:11}
\end{table}

Prawdopodobieństwo otrzymane za pomocą modelu jest identyczne jak to otrzymane z wykorzystaniem modelu. 

# Zadanie 9 

W tym zadaniu będziemy testować hipotezy zerowe przeciwko dwóm pewnym modelom, w których jeden jest pełny (zawierają wszystkie interakcje) a drugi jest nadmodelem modelu z hipotezy zerowej, ale nie jest modelem pełnym. Hipotezy testujemy na poziomie istotności $\alpha = 0.05$.

* $H_0$: Dane pochodzą z modelu $[1\:2\:3]$
przeciwko 
- $H_1$: Dane pochodzą z modelu pełnego $[123]$
- $H_1$: Dane pochodzą z modelu $[12\: 3]$

```{r, echo=FALSE}
df_W1 <- as.data.frame(ftable(personel$S,personel$W1,personel$Wyk))
names(df_W1) <- c('S', 'W1', 'Wyk', 'Freq')

df_P <- as.data.frame(ftable(personel$S,personel$P,personel$Wyk))
names(df_P) <- c('S', 'P', 'Wyk', 'Freq')
```

Przykładowy kod, w którym dopasowujemy modele do naszych danych:

```{r}
m_0 <- glm(Freq ~ S+W1+Wyk, data = df_W1, family = poisson)
m_1 <- glm(Freq ~ S+W1+Wyk+S*W1+Wyk*W1+S*Wyk+S*W1*Wyk, data = df_W1, family = poisson)
m_2 <- glm(Freq ~ S+W1+Wyk+S*W1, data = df_W1, family = poisson)
```

```{r, echo=FALSE}
test <- anova(m_0, m_1)
p_1 <- 1-pchisq(test$Deviance[2], df = test$Df[2])

test <- anova(m_0, m_2)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```

Prawdopodobieństwo dla pierwszej z hipotez alternatywnych `r p_1` oraz dla drugiej `r p_2` są mniejsze niż założony poziom istotności $\alpha$, więc odrzucamy hipotezę zerową.


* $H_0$: Dane pochodzą z modelu $[2\:13]$ 
przeciwko 
- $H_1$: Dane pochodzą z modelu $[123]$
- $H_1$: Dane pochodzą z modelu $[13\: 23]$

```{r}
m_0 <- glm(Freq ~ S+W1+Wyk+ S*Wyk, data = df_W1, family = poisson)
m_1 <- glm(Freq ~ S+W1+Wyk+S*W1+Wyk*W1+S*Wyk+S*W1*Wyk, data = df_W1, family = poisson)
m_2 <- glm(Freq ~ S+W1+Wyk+Wyk*W1+S*Wyk, data = df_W1, family = poisson)

test <- anova(m_0, m_1)
p_1 <- 1-pchisq(test$Deviance[2], df = test$Df[2])

test <- anova(m_0, m_2)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```
Prawdopodobieństwo dla pierwszej z hipotez alternatywnych `r p_1` jest większe niż założony poziom istotności, więc nie odrzucamy hipotezy zerowej. Natomiast dla drugiej `r p_2` jest mniejszy niż założony poziom istotności $\alpha$, więc odrzucamy hipotezę zerową.

* $H_0$: Dane pochodzą z modelu $[13\:23]$ 
przeciwko 
- $H_1$: Dane pochodzą z modelu $[123]$
- $H_1$: Dane pochodzą z modelu $[12\: 13\: 23]$

```{r}
m_0 <- glm(Freq ~ S+W1+Wyk+ S*Wyk+W1*Wyk, data = df_W1, family = poisson)
m_1 <- glm(Freq ~ S+W1+Wyk+S*W1+Wyk*W1+S*Wyk+S*W1*Wyk, data = df_W1, family = poisson)
m_2 <- glm(Freq ~ S+W1+Wyk+S*W1+Wyk*W1+S*Wyk+S*W1, data = df_W1, family = poisson)

test <- anova(m_0, m_1)
p_1 <- 1-pchisq(test$Deviance[2], df = test$Df[2])

test <- anova(m_0, m_2)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```

Prawdopodobieństwo dla pierwszej z hipotez alternatywnych `r p_1` oraz dla drugiej `r p_2` jest większe niż założony poziom istotności, więc nie mamy podstaw do odrzucenia hipotezy zerowej. 

* $H_0$: Dane pochodzą z modelu $[13\:23]$ 
przeciwko 
- $H_1$: Dane pochodzą z modelu $[123]$
- $H_1$: Dane pochodzą z modelu $[12\: 13\: 23]$

```{r}
m_0 <- glm(Freq ~ S+P+Wyk+S*Wyk+P*Wyk, data = df_P, family = poisson)
m_1 <- glm(Freq ~ S+P+Wyk+S*P+Wyk*P+S*Wyk+S*P*Wyk, data = df_P, family = poisson)
m_2 <- glm(Freq ~ S+P+Wyk+S*P+Wyk*P+S*Wyk+S*P, data = df_P, family = poisson)

test <- anova(m_0, m_1)
p_1 <- 1-pchisq(test$Deviance[2], df = test$Df[2])

test <- anova(m_0, m_2)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```

Prawdopodobieństwo dla drugiej z hipotez alternatywnych `r p_2` jest mniejszy niż założony poziom istotności $\alpha$, więc odrzucamy hipotezę zerową. Natomiast dla pierwszej `r p_1`
jest mniejszy, zatem nie mamy podstaw do odrzucenia hipotezy zerowej. 

# Zadanie 10

## Testy 
Wybór modelu w oparciu o testy  został wykonany w ten sposób, że najpierw wzięliśmy model, w którym nie występują żadne interakcje  $[1\;2\;3]$, wykonaliśmy test ilorazu wiarygodności, gdzie hipotezą alternatywną $H_1$ był nadmodel modelu z hipotezy alternatywnej. Jeśli uzyskana p-wartość była większa niż założony poziom istotności $\alpha=0.05$, to przyjmowaliśmy że model z hipotezy zerowej $H_0$ lepiej opisuje nasze dane, w przeciwnym wypadku, dla następnych testów, model z hipotezy alternatywnej stawał się modelem hipotezy zerowej.
Postępując w ten sposób doszliśmy do modelu, który według testów najlepiej opisuje dane.

* Model $[1\;2\;3]$ przeciwko $[12\;3]$
```{r}
df <- as.data.frame(ftable(personel$A1,personel$W1,personel$P))
names(df) <- c('A1', 'W1', 'P', 'Freq')

m_0 <- glm(Freq ~ A1+W1+P, data = df, family = poisson)
m_1 <- glm(Freq ~ A1+W1+W1+A1*W1, data = df, family = poisson)
test <- anova(m_0, m_1)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```
Otrzymana p-wartość `r p_2` jest mniejsza niż założony poziom istotności, więc odrzucamy hipotezę zerową. Model $[12\;3]$ staje się modelem wyjściowym.

* Model $[12\;3]$ przeciwko $[12\;13]$
```{r}
m_0 <- glm(Freq ~ A1+W1+P+A1*W1, data = df, family = poisson)
m_1 <- glm(Freq ~ A1+W1+P+A1*W1+A1*P, data = df, family = poisson)
test <- anova(m_0, m_1)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```
Otrzymana p-wartość `r p_2` jest większa niż założony poziom istotności, więc nie mamy podstaw do odrzucenia hipotezy zerowej. 

* Model $[12\;3]$ przeciwko $[12\;23]$
```{r}
m_0 <- glm(Freq ~ A1+W1+P+A1*W1, data = df, family = poisson)
m_1 <- glm(Freq ~ A1+W1+P+A1*W1+W1*P, data = df, family = poisson)
test <- anova(m_0, m_1)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```
Otrzymana p-wartość `r p_2` jest większa niż założony poziom istotności, więc nie mamy podstaw do odrzucenia hipotezy zerowej. 


* Model $[12\;3]$ przeciwko $[12\;13\;23]$
```{r}
m_0 <- glm(Freq ~ A1+W1+P+A1*W1, data = df, family = poisson)
m_1 <- glm(Freq ~ A1+W1+P+A1*W1+W1*P+P*A1, data = df, family = poisson)
test <- anova(m_0, m_1)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```

Otrzymana p-wartość `r p_2` jest większa niż założony poziom istotności, więc nie mamy podstaw do odrzucenia hipotezy zerowej. 


* Model $[12\;3]$ przeciwko $[123]$

```{r}
m_0 <- glm(Freq ~ A1+W1+P+A1*W1, data = df, family = poisson)
m_1 <- glm(Freq ~ A1+W1+P+A1*W1+W1*P+P*A1+A1*W1*P, data = df, family = poisson)
test <- anova(m_0, m_1)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```
Otrzymana p-wartość `r p_2` jest większa niż założony poziom istotności, więc nie mamy podstaw do odrzucenia hipotezy zerowej. 


Z przeprowadzonych testów wynika, że model $[12\;3]$ najlepiej opisuje nasze dane. 

## Kryterium AIC
```{r, echo=FALSE}
model_ <- glm(Freq ~ 1, data = df, family = poisson)
	model_1 <- glm(Freq ~ A1, data = df, family = poisson)
	model_2 <- glm(Freq ~ W1, data = df, family = poisson)
	model_3 <- glm(Freq ~ P, data = df, family = poisson)
	model_1_2 <- glm(Freq ~ A1 + W1, data = df, family = poisson)
	model_1_3 <- glm(Freq ~ A1 + P, data = df, family = poisson)
	model_2_3 <- glm(Freq ~ W1 + P, data = df, family = poisson)
	model_12 <- glm(Freq ~ A1+W1+A1*W1, data = df, family = poisson)
	model_13 <- glm(Freq ~ A1+P+A1*P, data = df, family = poisson)
	model_23 <- glm(Freq ~ W1+P+W1*P,
		data = df, family = poisson)
	model_1_2_3 <- glm(Freq ~ A1+W1+P,
		data = df, family = poisson)
	model_12_3 <- glm(Freq ~ A1+W1+P+A1*W1,
		data = df, family = poisson)
	model_13_2 <- glm(Freq ~ A1+W1+P+A1*P,
		data = df, family = poisson)
	model_1_23 <- glm(Freq ~ A1+W1+P+W1*P,
		data = df, family = poisson)
	model_12_23 <- glm(Freq ~ A1+W1+P+A1*W1+W1*P,
		data = df, family = poisson)
	model_13_23 <- glm(Freq ~ A1+W1+P+A1*P+W1*P,
		data = df, family = poisson)
	model_12_13 <- glm(Freq ~ A1+W1+P+A1*W1+A1*P,
		data = df, family = poisson)
	model_12_23_13 <- glm(Freq ~ A1+W1+P+A1*W1+W1*P+A1*P, data = df, family = poisson)
	model_123 <- glm(Freq ~ A1+W1+P+A1*W1+A1*P+W1*P+A1*W1*P,
		data = df, family = poisson)
```


```{r}
	models_AIC <- c(AIC(model_), AIC(model_1), AIC(model_2), AIC(model_3),
	AIC(model_1_2), AIC(model_1_3), AIC(model_2_3), AIC(model_12),
	AIC(model_13), AIC(model_23), AIC(model_1_2_3), AIC(model_12_3),
	AIC(model_13_2), AIC(model_1_23), AIC(model_12_23), AIC(model_13_23),
	AIC(model_12_13), AIC(model_12_23_13), AIC(model_123))
```

\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
Model & Wartość kryterium \\ \hline
$[]$     & `r models_AIC[1]` \\ \hline
$[1]$     & `r models_AIC[2]` \\ \hline
$[2]$     & `r models_AIC[3]` \\ \hline
$[3]$     & `r models_AIC[4]` \\ \hline
$[1\;2]$     & `r models_AIC[5]` \\ \hline
$[1\;3]$      &  `r models_AIC[6]`\\ \hline
$[2\;3]$      &  `r models_AIC[7]`\\ \hline
$[12]$      & `r models_AIC[8]`\\ \hline
$[13]$      & `r models_AIC[9]`\\ \hline
$[23]$      & `r models_AIC[10]`\\ \hline
$[1\;2\;3]$      &  `r models_AIC[11]`\\ \hline
$[12\;3]$      & `r models_AIC[12]`\\ \hline
$[13\;2]$      & `r models_AIC[13]`\\ \hline
$[1\;23]$      & `r models_AIC[14]`\\ \hline
$[12\;23]$      & `r models_AIC[15]` \\ \hline
$[13\;23]$      &  `r models_AIC[16]`\\ \hline
$[12\;13]$      &  `r models_AIC[17]`\\ \hline
$[12\;13\;23]$  & `r models_AIC[18]`\\ \hline
$[123]$      & `r models_AIC[19]`\\ \hline
\end{tabular}
\caption{Wartości obliczonych kryteriów AIC dla poszczególnych modeli}
\label{tab:12}
\end{table}
Najmniejsza wartość kryterium informacyjnego wynosi `r min(models_AIC)`, a otrzymano ją dla modelu $[12\;3]$, czyli tego samego który otrzymaliśmy z wykorzystaniem testów. 

## Kryterium BIC 

```{r}
	models_BIC <- c(BIC(model_), BIC(model_1), BIC(model_2), BIC(model_3),
	BIC(model_1_2), BIC(model_1_3), BIC(model_2_3), BIC(model_12),
	BIC(model_13), BIC(model_23), BIC(model_1_2_3), BIC(model_12_3),
	BIC(model_13_2), BIC(model_1_23), BIC(model_12_23), BIC(model_13_23),
	BIC(model_12_13), BIC(model_12_23_13), BIC(model_123))
```

\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
Model & Wartość kryterium \\ \hline
$[]$     & `r models_BIC[1]` \\ \hline
$[1]$     & `r models_BIC[2]` \\ \hline
$[2]$     & `r models_BIC[3]` \\ \hline
$[3]$     & `r models_BIC[4]` \\ \hline
$[1\;2]$     & `r models_BIC[5]` \\ \hline
$[1\;3]$      &  `r models_BIC[6]`\\ \hline
$[2\;3]$      &  `r models_BIC[7]`\\ \hline
$[12]$      & `r models_BIC[8]`\\ \hline
$[13]$      & `r models_BIC[9]`\\ \hline
$[23]$      & `r models_BIC[10]`\\ \hline
$[1\;2\;3]$      &  `r models_BIC[11]`\\ \hline
$[12\;3]$      & `r models_BIC[12]`\\ \hline
$[13\;2]$      & `r models_BIC[13]`\\ \hline
$[1\;23]$      & `r models_BIC[14]`\\ \hline
$[12\;23]$      & `r models_BIC[15]` \\ \hline
$[13\;23]$      &  `r models_BIC[16]`\\ \hline
$[12\;13]$      &  `r models_BIC[17]`\\ \hline
$[12\;13\;23]$  & `r models_BIC[18]`\\ \hline
$[123]$      & `r models_BIC[19]`\\ \hline
\end{tabular}
\caption{Wartości obliczonych kryteriów BIC dla poszczególnych modeli}
\label{tab:13}
\end{table}

Najmniejsza wartość kryterium informacyjnego wynosi `r min(models_BIC)`, a otrzymano ją dla modelu $[12\;3]$, czyli tego samego który otrzymaliśmy z wykorzystaniem testów i kryterium AIC. 

## Metoda krokowa 

```{r}
step(model_123)
```
Z wykorzystaniem metody krokowej otrzymaliśmy ten sam model, co wyżej. 


# Zadanie 11

```{r, echo=FALSE}
df <- as.data.frame(ftable(personel$D,personel$A1,personel$P))
names(df) <- c('D', 'A1', 'P', 'Freq')
model_ <- glm(Freq ~ 1, data = df, family = poisson)
	model_1 <- glm(Freq ~ D, data = df, family = poisson)
	model_2 <- glm(Freq ~ A1, data = df, family = poisson)
	model_3 <- glm(Freq ~ P, data = df, family = poisson)
	model_1_2 <- glm(Freq ~ D + A1, data = df, family = poisson)
	model_1_3 <- glm(Freq ~ D + P, data = df, family = poisson)
	model_2_3 <- glm(Freq ~ A1 + P, data = df, family = poisson)
	model_12 <- glm(Freq ~ D+A1+D*A1, data = df, family = poisson)
	model_13 <- glm(Freq ~ D+P+D*P, data = df, family = poisson)
	model_23 <- glm(Freq ~ A1+P+A1*P,
		data = df, family = poisson)
	model_1_2_3 <- glm(Freq ~ D+A1+P,
		data = df, family = poisson)
	model_12_3 <- glm(Freq ~ D+A1+P+D*A1,
		data = df, family = poisson)
	model_13_2 <- glm(Freq ~ D+A1+P+D*P,
		data = df, family = poisson)
	model_1_23 <- glm(Freq ~ D+A1+P+A1*P,
		data = df, family = poisson)
	model_12_23 <- glm(Freq ~ D+A1+P+D*A1+A1*P,
		data = df, family = poisson)
	model_13_23 <- glm(Freq ~ D+A1+P+D*P+A1*P,
		data = df, family = poisson)
	model_12_13 <- glm(Freq ~ D+A1+P+D*A1+D*P,
		data = df, family = poisson)
	model_12_23_13 <- glm(Freq ~ D+A1+P+D*A1+A1*P+D*P, data = df, family = poisson)
	model_123 <- glm(Freq ~ D+A1+P+D*A1+D*P+A1*P+D*A1*P,
		data = df, family = poisson)  
```

## Testy 

Analogicznie jak w zadaniu 10. 

* Model $[1\;2\;3]$ przeciwko $[12\;3]$
```{r}
m_0 <- glm(Freq ~ D+A1+P, data = df, family = poisson)
m_1 <- glm(Freq ~ D+A1+P+D*A1, data = df, family = poisson)
test <- anova(m_0, m_1)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```
Otrzymana p-wartość `r p_2` jest większa niż założony poziom istotności, więc nie mamy podstaw do odrzucenia hipotezy zerowej. 

* Model $[1\;2\;3]$ przeciwko $[1\;23]$
```{r}
m_0 <- glm(Freq ~ D+A1+P, data = df, family = poisson)
m_1 <- glm(Freq ~ D+A1+P+P*A1, data = df, family = poisson)
test <- anova(m_0, m_1)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```

Otrzymana p-wartość `r p_2` jest większa niż założony poziom istotności, więc nie mamy podstaw do odrzucenia hipotezy zerowej.

* Model $[1\;2\;3]$ przeciwko $[13\;2]$
```{r}
m_0 <- glm(Freq ~ D+A1+P, data = df, family = poisson)
m_1 <- glm(Freq ~ D+A1+P+D*P, data = df, family = poisson)
test <- anova(m_0, m_1)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```

Otrzymana p-wartość `r p_2` jest mniejsza niż założony poziom istotności, więc odrzucamy hipotezę zerową. Model $[13\;2]$ staje się modelem wyjściowym.

* Model $[13\;2]$ przeciwko $[12\;13]$
```{r}
m_0 <- glm(Freq ~ D+A1+P+D*P, data = df, family = poisson)
m_1 <- glm(Freq ~ D+A1+P+D*A1+D*P, data = df, family = poisson)
test <- anova(m_0, m_1)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```

Otrzymana p-wartość `r p_2` jest większa niż założony poziom istotności, więc nie mamy podstaw do odrzucenia hipotezy zerowej.

* Model $[13\;2]$ przeciwko $[13\;23]$
```{r}
m_0 <- glm(Freq ~ D+A1+P+D*P, data = df, family = poisson)
m_1 <- glm(Freq ~ D+A1+P+D*P+A1*P, data = df, family = poisson)
test <- anova(m_0, m_1)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```

Otrzymana p-wartość `r p_2` jest większa niż założony poziom istotności, więc nie mamy podstaw do odrzucenia hipotezy zerowej.

* Model $[13\;2]$ przeciwko $[12\;23]$
```{r}
m_0 <- glm(Freq ~ D+A1+P+D*P, data = df, family = poisson)
m_1 <- glm(Freq ~ D+A1+P+D*A1+A1*P, data = df, family = poisson)
test <- anova(m_0, m_1)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```

Otrzymana p-wartość `r p_2` jest większa niż założony poziom istotności, więc nie mamy podstaw do odrzucenia hipotezy zerowej.

* Model $[13\;2]$ przeciwko $[12\;13\;23]$
```{r}
m_0 <- glm(Freq ~ D+A1+P+D*P, data = df, family = poisson)
m_1 <- glm(Freq ~ D+A1+P+D*A1+A1*P+D*P, data = df, family = poisson)
test <- anova(m_0, m_1)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```

Otrzymana p-wartość `r p_2` jest większa niż założony poziom istotności, więc nie mamy podstaw do odrzucenia hipotezy zerowej.

* Model $[13\;2]$ przeciwko $[123]$
```{r}
m_0 <- glm(Freq ~ D+A1+P+D*P, data = df, family = poisson)
m_1 <- glm(Freq ~ D+A1+P+D*A1+A1*P+D*P+A1*P*D, data = df, family = poisson)
test <- anova(m_0, m_1)
p_2 <- 1-pchisq(test$Deviance[2], df = test$Df[2])
```

Otrzymana p-wartość `r p_2` jest większa niż założony poziom istotności, więc nie mamy podstaw do odrzucenia hipotezy zerowej.

Z przeprowadzonych testów wynika, że model $[13\;2]$ najlepiej opisuje nasze dane. 

## Kryterium AIC 

```{r}
models_AIC <- c(AIC(model_), AIC(model_1), AIC(model_2), AIC(model_3),
	AIC(model_1_2), AIC(model_1_3), AIC(model_2_3), AIC(model_12),
	AIC(model_13), AIC(model_23), AIC(model_1_2_3), AIC(model_12_3),
	AIC(model_13_2), AIC(model_1_23), AIC(model_12_23), AIC(model_13_23),
	AIC(model_12_13), AIC(model_12_23_13), AIC(model_123))
```

\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
Model & Wartość kryterium \\ \hline
$[]$     & `r models_AIC[1]` \\ \hline
$[1]$     & `r models_AIC[2]` \\ \hline
$[2]$     & `r models_AIC[3]` \\ \hline
$[3]$     & `r models_AIC[4]` \\ \hline
$[1\;2]$     & `r models_AIC[5]` \\ \hline
$[1\;3]$      &  `r models_AIC[6]`\\ \hline
$[2\;3]$      &  `r models_AIC[7]`\\ \hline
$[12]$      & `r models_AIC[8]`\\ \hline
$[13]$      & `r models_AIC[9]`\\ \hline
$[23]$      & `r models_AIC[10]`\\ \hline
$[1\;2\;3]$      &  `r models_AIC[11]`\\ \hline
$[12\;3]$      & `r models_AIC[12]`\\ \hline
$[13\;2]$      & `r models_AIC[13]`\\ \hline
$[1\;23]$      & `r models_AIC[14]`\\ \hline
$[12\;23]$      & `r models_AIC[15]` \\ \hline
$[13\;23]$      &  `r models_AIC[16]`\\ \hline
$[12\;13]$      &  `r models_AIC[17]`\\ \hline
$[12\;13\;23]$  & `r models_AIC[18]`\\ \hline
$[123]$      & `r models_AIC[19]`\\ \hline
\end{tabular}
\caption{Wartości obliczonych kryteriów AIC dla poszczególnych modeli}
\label{tab:14}
\end{table}

Najmniejsza wartość kryterium informacyjnego wynosi `r min(models_AIC)`, a otrzymano ją dla modelu $[13\;2]$, czyli tego samego który otrzymaliśmy z wykorzystaniem testów. 

## Kryterium BIC

```{r}
	models_BIC <- c(BIC(model_), BIC(model_1), BIC(model_2), BIC(model_3),
	BIC(model_1_2), BIC(model_1_3), BIC(model_2_3), BIC(model_12),
	BIC(model_13), BIC(model_23), BIC(model_1_2_3), BIC(model_12_3),
	BIC(model_13_2), BIC(model_1_23), BIC(model_12_23), BIC(model_13_23),
	BIC(model_12_13), BIC(model_12_23_13), BIC(model_123))
```

\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
Model & Wartość kryterium \\ \hline
$[]$     & `r models_BIC[1]` \\ \hline
$[1]$     & `r models_BIC[2]` \\ \hline
$[2]$     & `r models_BIC[3]` \\ \hline
$[3]$     & `r models_BIC[4]` \\ \hline
$[1\;2]$     & `r models_BIC[5]` \\ \hline
$[1\;3]$      &  `r models_BIC[6]`\\ \hline
$[2\;3]$      &  `r models_BIC[7]`\\ \hline
$[12]$      & `r models_BIC[8]`\\ \hline
$[13]$      & `r models_BIC[9]`\\ \hline
$[23]$      & `r models_BIC[10]`\\ \hline
$[1\;2\;3]$      &  `r models_BIC[11]`\\ \hline
$[12\;3]$      & `r models_BIC[12]`\\ \hline
$[13\;2]$      & `r models_BIC[13]`\\ \hline
$[1\;23]$      & `r models_BIC[14]`\\ \hline
$[12\;23]$      & `r models_BIC[15]` \\ \hline
$[13\;23]$      &  `r models_BIC[16]`\\ \hline
$[12\;13]$      &  `r models_BIC[17]`\\ \hline
$[12\;13\;23]$  & `r models_BIC[18]`\\ \hline
$[123]$      & `r models_BIC[19]`\\ \hline
\end{tabular}
\caption{Wartości obliczonych kryteriów BIC dla poszczególnych modeli}
\label{tab:15}
\end{table}

Najmniejsza wartość kryterium informacyjnego wynosi `r min(models_BIC)`, a otrzymano ją dla modelu $[13\;2]$, czyli tego samego który otrzymaliśmy z wykorzystaniem testów i kryterium AIC.

## Metoda krokowa 
```{r}
step(model_123)
```
Z wykorzystaniem metody krokowej otrzymaliśmy ten sam model, co z wykorzystaniem metod wyżej. 
